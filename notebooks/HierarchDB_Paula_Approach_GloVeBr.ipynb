{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1khq46I-mYIwg_EU-x6frkpJOx00gZHvX","authorship_tag":"ABX9TyMdeW8Ul5r+L2s+IniT09Ry"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMvDyndPDxMV","executionInfo":{"status":"ok","timestamp":1682602505277,"user_tz":180,"elapsed":38540,"user":{"displayName":"EDUARDO JOSE DA SILVA LUZ","userId":"04694447128035841155"}},"outputId":"494b731c-c1e0-44a1-ab2f-e12ab4087f20"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install gensim\n","!pip install xgboost\n"],"metadata":{"id":"vs5LwHTvAv2m","executionInfo":{"status":"ok","timestamp":1682602513768,"user_tz":180,"elapsed":8506,"user":{"displayName":"EDUARDO JOSE DA SILVA LUZ","userId":"04694447128035841155"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed650ba0-6287-4d85-8565-5322178e1f3b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n"]}]},{"cell_type":"code","source":["#baixe GloVe \n","#!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s300.zip\n","#!unzip glove_s300.zip\n","#!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove.6B.300d-pt.zip\n","#!unzip glove.6B.300d-pt.txt\n","\n","#%cd \"/content/drive/MyDrive/Colab Notebooks/2023/SBBD_toxic\"\n","#!pwd\n","#!unzip '/content/drive/MyDrive/Colab Notebooks/2023/SBBD_toxic/glove_s300.zip'\n","\n","#glove_file = \"glove_s300.txt\"\n","#glove_embeddings = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n"],"metadata":{"id":"ZVz_wCT9Bb8U","executionInfo":{"status":"ok","timestamp":1682602513769,"user_tz":180,"elapsed":12,"user":{"displayName":"EDUARDO JOSE DA SILVA LUZ","userId":"04694447128035841155"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import KeyedVectors\n","from sklearn.model_selection import train_test_split\n","\n","# Substitua o 'caminho_do_arquivo_treino.csv' pelo caminho real do seu arquivo CSV de treino\n","arquivo_csv_treino = '/content/drive/MyDrive/Colab Notebooks/2023/SBBD_toxic/data/hate_speech_data_paula.csv'\n","dados_treino = pd.read_csv(arquivo_csv_treino)\n","\n","# Pré-processamento dos dados de treino\n","X = dados_treino.iloc[:, 0]  # Coluna dos dados preprocessados\n","y = dados_treino.iloc[:, 1]  # Coluna dos rótulos\n","\n","# Dividir os dados em conjuntos de treino e validação\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","train_df = pd.DataFrame({'text': X_train, 'labels': y_train})\n","eval_df = pd.DataFrame({'text': X_val, 'labels': y_val})"],"metadata":{"id":"TsF6XlVFesoT","executionInfo":{"status":"ok","timestamp":1682602518044,"user_tz":180,"elapsed":4286,"user":{"displayName":"EDUARDO JOSE DA SILVA LUZ","userId":"04694447128035841155"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import string\n","from gensim.parsing.preprocessing import remove_stopwords\n","from gensim.models import KeyedVectors\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input\n","from tensorflow.keras.optimizers import Adam\n","import xgboost as xgb\n","\n","# Função de pré-processamento\n","def preprocess(text):\n","    text = text.lower()  # Transformar para minúsculas\n","    text = remove_stopwords(text)  # Remover stopwords usando Gensim\n","    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)  # Remover pontuação\n","    return text\n","\n","# Aplicar pré-processamento nos conjuntos de dados\n","train_df['text'] = train_df['text'].apply(preprocess)\n","eval_df['text'] = eval_df['text'].apply(preprocess)\n","\n","# Carregar word embeddings pré-treinados\n","# Caminho para o arquivo de vetores de palavra GloVe\n","#glove_file_path = '/content/drive/MyDrive/Colab Notebooks/2023/SBBD_toxic/glove_s300.txt'glove.6B.300d.txt\n","glove_file_path = '/content/drive/MyDrive/Colab Notebooks/2023/SBBD_toxic/glove.6B.300d.txt'\n","\n","# Carregar os vetores de palavra GloVe em um dicionário\n","embeddings_index = {}\n","with open(glove_file_path, encoding='utf8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = coefs\n","\n","\n","# Tokenização e padding\n","max_length = 280\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_df['text'])\n","word_index = tokenizer.word_index\n","\n","train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n","train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n","\n","eval_sequences = tokenizer.texts_to_sequences(eval_df['text'])\n","eval_padded = pad_sequences(eval_sequences, maxlen=max_length, padding='post', truncating='post')\n","\n","# Preparar matriz de embeddings\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 300\n","\n","embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","# Definir a arquitetura do modelo LSTM\n","inputs = Input(shape=(max_length,))\n","x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(inputs)\n","x = LSTM(50, return_sequences=True)(x)\n","x = Dropout(0.5)(x)\n","x = LSTM(50)(x)\n","x = Dropout(0.5)(x)\n","outputs = Dense(1, activation='sigmoid')(x)\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","# Compilar e treinar o modelo\n","model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(train_padded, train_df['labels'], epochs=10, batch_size=128, validation_split=0.1)\n","\n","# Remover a última camada (softmax) do modelo para extrair características\n","feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n","\n","#Extrair características do conjunto de teste\n","train_features = feature_extractor.predict(train_padded)\n","eval_features = feature_extractor.predict(eval_padded)\n","\n","#Treinar um classificador XGBoost com as características extraídas\n","xgb_classifier = xgb.XGBClassifier()\n","#xgb_classifier.fit(eval_features, eval_df['labels'])\n","xgb_classifier.fit(train_features, train_df['labels'])\n","\n","#Avaliar o classificador XGBoost\n","xgb_preds = xgb_classifier.predict(eval_features)\n","xgb_f1 = f1_score(eval_df['labels'], xgb_preds)\n","xgb_precision = precision_score(eval_df['labels'], xgb_preds)\n","xgb_recall = recall_score(eval_df['labels'], xgb_preds)\n","\n","print(f'XGBoost F1 Score: {xgb_f1}')\n","print(f'XGBoost Precision: {xgb_precision}')\n","print(f'XGBoost Recall: {xgb_recall}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBAxmr1vCjtf","executionInfo":{"status":"ok","timestamp":1682602779081,"user_tz":180,"elapsed":66894,"user":{"displayName":"EDUARDO JOSE DA SILVA LUZ","userId":"04694447128035841155"}},"outputId":"bc37aa8e-ed06-476f-b13a-16776c5f0bd8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","32/32 [==============================] - 13s 58ms/step - loss: 0.6424 - accuracy: 0.6854 - val_loss: 0.6447 - val_accuracy: 0.6586\n","Epoch 2/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6242 - accuracy: 0.6854 - val_loss: 0.6432 - val_accuracy: 0.6586\n","Epoch 3/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6249 - accuracy: 0.6854 - val_loss: 0.6438 - val_accuracy: 0.6586\n","Epoch 4/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.6260 - accuracy: 0.6854 - val_loss: 0.6420 - val_accuracy: 0.6586\n","Epoch 5/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6276 - accuracy: 0.6854 - val_loss: 0.6476 - val_accuracy: 0.6586\n","Epoch 6/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6276 - accuracy: 0.6854 - val_loss: 0.6421 - val_accuracy: 0.6586\n","Epoch 7/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6260 - accuracy: 0.6854 - val_loss: 0.6420 - val_accuracy: 0.6586\n","Epoch 8/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6260 - accuracy: 0.6854 - val_loss: 0.6438 - val_accuracy: 0.6586\n","Epoch 9/10\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6252 - accuracy: 0.6854 - val_loss: 0.6428 - val_accuracy: 0.6586\n","Epoch 10/10\n","32/32 [==============================] - 1s 27ms/step - loss: 0.6237 - accuracy: 0.6854 - val_loss: 0.6423 - val_accuracy: 0.6586\n","142/142 [==============================] - 2s 9ms/step\n","36/36 [==============================] - 0s 7ms/step\n","XGBoost F1 Score: 0.21052631578947367\n","XGBoost Precision: 0.30434782608695654\n","XGBoost Recall: 0.16091954022988506\n"]}]}]}