# Detecção de Discurso de Ódio: Uma abordagem Centrada em Dados

A emergência de modelos de linguagem de grande escala tem revolucionado o campo do processamento de linguagem natural, prometendo avanços significativos em tarefas como a detecção de discurso de ódio. Este estudo se concentra em avaliar a eficácia desses modelos, especificamente no contexto do português brasileiro, utilizando dois conjuntos de dados: um balanceado, extraído da literatura, e um inédito, desbalanceado, desenvolvido para esta pesquisa. Através de uma análise comparativa de modelos como Bertimbau, ChatGPT 3.5-turbo, ChatGPT 4, entre outros, investigamos métricas como precisão, f-score e acurácia. O trabalho revela variações significativas no desempenho dos modelos entre os conjuntos de dados, destacando o impacto da qualidade e da natureza dos dados no treinamento desses sistemas. Além disso, a introdução de um novo conjunto de dados inédito busca enriquecer as ferramentas disponíveis para futuras pesquisas, oferecendo novas perspectivas sobre a generalização de modelos em cenários desbalanceados. Os resultados indicam que, apesar dos desafios, é possível alcançar bons níveis de precisão na detecção de discurso de ódio, sublinhando a relevância de otimizações específicas e da seleção cuidadosa dos dados de treinamento.
